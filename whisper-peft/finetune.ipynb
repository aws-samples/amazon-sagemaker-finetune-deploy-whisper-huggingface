{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a53b642-9b81-40f4-9619-d4c303aacd73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::348052051973:role/service-role/AmazonSageMaker-ExecutionRole-20221220T150158\n",
      "sagemaker bucket: sagemaker-us-east-1-348052051973\n",
      "sagemaker session region: us-east-1\n",
      "data uri: s3://sagemaker-us-east-1-348052051973/whisper/data/marathi-common-voice-processed\n"
     ]
    }
   ],
   "source": [
    "# Initialize sagemaker session and get the training data s3 uri\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "import os\n",
    "\n",
    "#BUCKET=\"[BUCKET_NAME]\" # please use your bucket name if you are not using the default bucket\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "BUCKET = sess.default_bucket()\n",
    "PREFIX = \"whisper/data/marathi-common-voice-processed\"\n",
    "s3uri = os.path.join(\"s3://\", BUCKET, PREFIX)\n",
    "print(f\"sagemaker role arn: {ROLE}\")\n",
    "print(f\"sagemaker bucket: {BUCKET}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"data uri: {s3uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f73d376-00a3-4b8b-8868-6e2f69ea0033",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Some training parameters\n",
    "# For distributed training\n",
    "# distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "# instance_type = 'ml.p4d.24xlarge'\n",
    "# training_batch_size  = 4\n",
    "# eval_batch_size = 2\n",
    "\n",
    "# For single instance training\n",
    "distribution = None\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "training_batch_size  = 16\n",
    "eval_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5c5b536-d310-465e-89cd-0ac47a41ad7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name:  whisper-mr-1686399110\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# Create an unique id to tag training job and model name. \n",
    "id = int(time.time())\n",
    "\n",
    "TRAINING_JOB_NAME = f\"whisper-mr-{id}\"\n",
    "print('Training job name: ', TRAINING_JOB_NAME)\n",
    "\n",
    "# hyperparameters = {'num_train_epochs':3, # you can increase the max steps to improve model accuracy\n",
    "#                    'train_batch_size': training_batch_size,\n",
    "#                    'eval_batch_size': eval_batch_size,\n",
    "#                    'model_name': \"openai/whisper-large-v2\",\n",
    "#                    'language': \"Marathi\",\n",
    "#                    'dataloader_num_workers': 16,\n",
    "#                   }\n",
    "\n",
    "model_name_s3 = \"whisper-large-v2\"\n",
    "environment = {\n",
    "              'MODEL_S3_BUCKET': BUCKET, # The bucket to store pretrained model and fine-tune model\n",
    "              'MODEL_NAME_S3': model_name_s3,\n",
    "              'DATA_S3': s3uri,\n",
    "}\n",
    "\n",
    "# Define metrics definitions, such metrics will be extracted from training script's printed logs and send to cloudwatch\n",
    "metric_definitions=[\n",
    "        {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'eval_wer', 'Regex': \"'eval_wer': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbeff9ac-fdf0-4ce7-9315-c93d93809eb4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Point the training data to the s3 uri. Use FastFile to \"mount\" the s3 files directly instead of copying to local disk\n",
    "from sagemaker.inputs import TrainingInput\n",
    "training_input_path=s3uri\n",
    "\n",
    "training = TrainingInput(\n",
    "    s3_data_type='S3Prefix', # Available Options: S3Prefix | ManifestFile | AugmentedManifestFile\n",
    "    s3_data=training_input_path,\n",
    "    distribution='FullyReplicated', # Available Options: FullyReplicated | ShardedByS3Key \n",
    "    input_mode='FastFile'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41852f30-0d50-41bc-8840-d121ca90d95b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: whisper-mr-1686399110\n"
     ]
    }
   ],
   "source": [
    "# Create the HuggingFace Estimator and kick off the training with \"fit\". Note that as of the writing, the latest hugging face training image has version of transformers_version='4.17.0' and pytorch_version='1.10.2', the transformer version can be upgraded in the requirements.txt.\n",
    "# More details on training images, see https://github.com/aws/deep-learning-containers/blob/master/available_images.md\n",
    "OUTPUT_PATH= f's3://{BUCKET}/{PREFIX}/{TRAINING_JOB_NAME}/output/'\n",
    "\n",
    "huggingface_estimator = HuggingFace(entry_point='train.sh',\n",
    "                                    source_dir='./src',\n",
    "                                    output_path= OUTPUT_PATH, \n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=1,\n",
    "                                    # transformers_version='4.17.0',\n",
    "                                    # pytorch_version='1.10.2',\n",
    "                                    py_version='py310',\n",
    "                                    image_uri='348052051973.dkr.ecr.us-east-1.amazonaws.com/whisper:training',\n",
    "                                    role=ROLE,\n",
    "                                    # hyperparameters = hyperparameters,\n",
    "                                    metric_definitions = metric_definitions,\n",
    "                                    volume_size=200,\n",
    "                                    distribution=distribution,\n",
    "                                    keep_alive_period_in_seconds=1800,\n",
    "                                    environment=environment,\n",
    "                                   )\n",
    "\n",
    "#Starts the training job using the fit function, training takes approximately 2 hours to complete.\n",
    "# huggingface_estimator.fit({'train': training}, job_name=TRAINING_JOB_NAME)\n",
    "huggingface_estimator.fit(job_name=TRAINING_JOB_NAME, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f90adb8-b0ad-42d6-ba36-8a848587e907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/output/2023-06-10-18-48-26/whisper_out/adapter_model/README.md adapter_model/README.md\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/output/2023-06-10-18-48-26/whisper_out/adapter_model/adapter_config.json adapter_model/adapter_config.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/output/2023-06-10-18-48-26/whisper_out/adapter_model/adapter_model.bin adapter_model/adapter_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Download the trained adaptor model\n",
    "!./s5cmd sync s3://sagemaker-us-east-1-348052051973/whisper-large-v2/output/2023-06-10-18-48-26/whisper_out/adapter_model/* adapter_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0251369-0132-47f6-82f5-25863ce8195b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/generation_config.json /tmp/whisper-large-v2/generation_config.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/added_tokens.json /tmp/whisper-large-v2/added_tokens.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/tokenizer_config.json /tmp/whisper-large-v2/tokenizer_config.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/normalizer.json /tmp/whisper-large-v2/normalizer.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/preprocessor_config.json /tmp/whisper-large-v2/preprocessor_config.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/merges.txt /tmp/whisper-large-v2/merges.txt\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/special_tokens_map.json /tmp/whisper-large-v2/special_tokens_map.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/config.json /tmp/whisper-large-v2/config.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/tokenizer.json /tmp/whisper-large-v2/tokenizer.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/vocab.json /tmp/whisper-large-v2/vocab.json\n",
      "cp s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/pytorch_model.bin /tmp/whisper-large-v2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Download the original model if not on local disk\n",
    "!./s5cmd sync s3://sagemaker-us-east-1-348052051973/whisper-large-v2/pretrain/* /tmp/whisper-large-v2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9aa6c-30cd-4bd7-9f41-008624a08e6b",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4bfcc02-863f-4a5e-b919-20c9a656461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import WhisperForConditionalGeneration, Seq2SeqTrainer\n",
    "\n",
    "peft_model_id = \"adapter_model\"\n",
    "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "105f2729-afe6-4d2b-ae5a-b0ce4711b790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "common_voice = load_from_disk(\"marathi-common-voice-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3b408b1-f04b-433d-92d9-576bda6211fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8e63f9f-65b6-490c-ab02-52d560814bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "model_name_or_path = \"/tmp/whisper-large-v2\"\n",
    "language = \"Marathi\"\n",
    "language_abbr = \"mr\"\n",
    "task = \"transcribe\"\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da300b23-fd13-4793-883b-e32d6afb3a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/227 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "100%|██████████| 227/227 [1:44:51<00:00, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer=41.5447102056605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "eval_dataloader = DataLoader(common_voice[\"test\"], batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = (\n",
    "                model.generate(\n",
    "                    input_features=batch[\"input_features\"].to(\"cuda\"),\n",
    "                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),\n",
    "                    max_new_tokens=255,\n",
    "                )\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            metric.add_batch(\n",
    "                predictions=decoded_preds,\n",
    "                references=decoded_labels,\n",
    "            )\n",
    "    del generated_tokens, labels, batch\n",
    "    gc.collect()\n",
    "wer = 100 * metric.compute()\n",
    "print(f\"{wer=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00fab2-4717-416a-a02d-1e1cc3cca3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "python3 (pytorch2/2)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:348052051973:image-version/pytorch2/2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
