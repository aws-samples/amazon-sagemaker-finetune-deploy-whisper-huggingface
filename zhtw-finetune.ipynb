{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53b642-9b81-40f4-9619-d4c303aacd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize sagemaker session and get the training data s3 uri\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "import os\n",
    "\n",
    "#BUCKET=\"[BUCKET_NAME]\" # please use your bucket name if you are not using the default bucket\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "BUCKET = sess.default_bucket()\n",
    "PREFIX = \"whisper/data/zhtw-common-voice-processed\"\n",
    "s3uri = os.path.join(\"s3://\", BUCKET, PREFIX)\n",
    "print(f\"sagemaker role arn: {ROLE}\")\n",
    "print(f\"sagemaker bucket: {BUCKET}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"data uri: {s3uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73d376-00a3-4b8b-8868-6e2f69ea0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some training parameters\n",
    "# For distributed training\n",
    "# distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "# instance_type = 'ml.p3.16xlarge'\n",
    "# training_batch_size  = 4\n",
    "# eval_batch_size = 2\n",
    "\n",
    "# For single instance training\n",
    "distribution = None\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "training_batch_size  = 16\n",
    "eval_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5b536-d310-465e-89cd-0ac47a41ad7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# Create an unique id to tag training job and model name. \n",
    "id = int(time.time())\n",
    "\n",
    "TRAINING_JOB_NAME = f\"whisper-zhtw-{id}\"\n",
    "print('Training job name: ', TRAINING_JOB_NAME)\n",
    "\n",
    "hyperparameters = {'max_steps':16000, # you can increase the max steps to improve model accuracy\n",
    "                   'train_batch_size': training_batch_size,\n",
    "                   'eval_batch_size': eval_batch_size,\n",
    "                   'model_name': \"openai/whisper-small\",\n",
    "                   'language': \"Chinese\",\n",
    "                   'dataloader_num_workers': 16,\n",
    "                  }\n",
    "\n",
    "# Define metrics definitions, such metrics will be extracted from training script's printed logs and send to cloudwatch\n",
    "metric_definitions=[\n",
    "        {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'eval_wer', 'Regex': \"'eval_wer': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeff9ac-fdf0-4ce7-9315-c93d93809eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Point the training data to the s3 uri. Use FastFile to \"mount\" the s3 files directly instead of copying to local disk\n",
    "from sagemaker.inputs import TrainingInput\n",
    "training_input_path=s3uri\n",
    "\n",
    "training = TrainingInput(\n",
    "    s3_data_type='S3Prefix', # Available Options: S3Prefix | ManifestFile | AugmentedManifestFile\n",
    "    s3_data=training_input_path,\n",
    "    distribution='FullyReplicated', # Available Options: FullyReplicated | ShardedByS3Key \n",
    "    input_mode='FastFile'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41852f30-0d50-41bc-8840-d121ca90d95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the HuggingFace Estimator and kick off the training with \"fit\". Note that as of the writing, the latest hugging face training image has version of transformers_version='4.17.0' and pytorch_version='1.10.2', the transformer version can be upgraded in the requirements.txt.\n",
    "# More details on training images, see https://github.com/aws/deep-learning-containers/blob/master/available_images.md\n",
    "OUTPUT_PATH= f's3://{BUCKET}/{PREFIX}/{TRAINING_JOB_NAME}/output/'\n",
    "\n",
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                                    source_dir='./scripts',\n",
    "                                    output_path= OUTPUT_PATH, \n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=1,\n",
    "                                    transformers_version='4.17.0',\n",
    "                                    pytorch_version='1.10.2',\n",
    "                                    py_version='py38',\n",
    "                                    role=ROLE,\n",
    "                                    hyperparameters = hyperparameters,\n",
    "                                    metric_definitions = metric_definitions,\n",
    "                                    volume_size=200,\n",
    "                                    distribution=distribution,\n",
    "                                   )\n",
    "\n",
    "#Starts the training job using the fit function, training takes approximately 2 hours to complete.\n",
    "huggingface_estimator.fit({'train': training}, job_name=TRAINING_JOB_NAME)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
