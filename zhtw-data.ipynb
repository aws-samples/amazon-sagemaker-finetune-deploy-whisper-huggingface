{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b28b3-aae8-40f7-bd09-7a4499e6622c",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ml.m5.2xlarge instance with Data Science Kernel, restart the kernel after the installation\n",
    "!conda install pytorch torchvision torchaudio -c pytorch -y\n",
    "!conda install -c conda-forge tensorboard -y\n",
    "!conda install -c conda-forge tqdm -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76328662-ac06-4684-875c-228cd7f355b3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#install git lfs (required by hugging face model)\n",
    "!apt install gnupg -y\n",
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "!apt install -y git-lfs -y\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5afe73-7047-45ea-b2b4-813eef8fe8fd",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Check pytorch successfully installed with CUDA enabled if using GPU instance\n",
    "import torch\n",
    "# torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c544a-6ba7-4cf0-b005-6fbd7b08235d",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ffmpeg 4 is required for pytorch to process mp3\n",
    "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
    "!apt update\n",
    "!apt install -y ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029a687-d239-45de-bef6-e5d81dc30b91",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#install transformers and other dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.3.0\n",
    "!pip install jiwer\n",
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b1311-ca21-46a8-acf7-bd56ebb3c4f0",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Download common voice dataset\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = \\\n",
    "                load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-TW\", \\\n",
    "                             split=[\"train\", \"validation\", \"test\"], use_auth_token=False)\n",
    "\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c3ff5-0d5a-4814-9d5a-c42f755075d4",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Assign corresponding splits into the dataset\n",
    "common_voice[\"train\"]=train_dataset\n",
    "common_voice[\"validation\"]=validation_dataset\n",
    "common_voice[\"test\"]=test_dataset\n",
    "print(common_voice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc221a-dfe4-498e-ac0e-4e50355a63a6",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Save the dataset to disk so that we can recover the dataset more easily.\n",
    "common_voice.save_to_disk(\"zhtw-common-voice-original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9fada-8203-46ff-99ab-5f120a19ffdb",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Remove unneeded field for the training\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "common_voice = load_from_disk(\"zhtw-common-voice-original\")\n",
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \n",
    "                                            \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0f1f3-38bf-4760-830f-ae52194d6b2b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Let's start from the pretrained small model\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Chinese\", task=\"transcribe\")\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06333e-a90e-4120-8395-b71c4141df27",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Verify that tokenizer works both ways\n",
    "input_str = common_voice[\"train\"][0][\"sentence\"]\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ee654-1be2-49af-9d09-f5561317b571",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Let's view a sample\n",
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2427d70-71cf-49b4-b437-71c0e94a382b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Downsample the samples\n",
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "print(common_voice[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda9495-2482-4676-b98c-fa1cab620ea1",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Define the extraction function\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24cb59-dfcc-4349-ad12-8839aa0eac65",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Apply it to the whole dataset. Give it some time even all lines goes green.\n",
    "# If the process failed, try delete the cache-xxxx arrow files under zhtw-common-voice-original/train or the ~/.cache and restart the kernel.\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60224361-5d28-47a6-a22f-8ad9ca51e3c6",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Save the processed dataset to disk\n",
    "common_voice.save_to_disk(\"zhtw-common-voice-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe693fe9-5902-4e0e-b8a8-d73d417da00b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc5613-a79d-4b60-ab74-4d1f9d8e0ee2",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#View the default bucket location\n",
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "ROLE = get_execution_role()\n",
    "\n",
    "BUCKET = sess.default_bucket() \n",
    "PREFIX = \"whisper/data/zhtw-common-voice-processed\"\n",
    "s3uri = os.path.join(\"s3://\", BUCKET, PREFIX)\n",
    "s3uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7719c-4fbe-4025-b414-15045cdd6d80",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Use the aws s3 cli to upload the processed dataset. You could also choose to use the boto3 python sdk to do the upload.\n",
    "!aws s3 cp --recursive zhtw-common-voice-processed YOUR_S3_URI"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}