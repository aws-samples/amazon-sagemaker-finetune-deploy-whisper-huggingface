{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cd748-d4d4-4f03-945b-4150159c5541",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upgrade packages and install libsndfile1\n",
    "!sudo yum upgrade -y\n",
    "!sudo yum install libsndfile1 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499639bf-5964-41dc-8122-eca34587f127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install librosa (if you want to process mp3) and upgrade sagemaker\n",
    "!pip install librosa\n",
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769ebd1-629b-4b05-b6fa-177e3cb522c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker.huggingface\n",
    "\n",
    "#BUCKET=\"[BUCKET_NAME]\" # please use your bucket name\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "BUCKET = sess.default_bucket()\n",
    "print(f\"sagemaker role arn: {ROLE}\")\n",
    "print(f\"sagemaker bucket: {BUCKET}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e3fee-0a1f-4b2a-b3ef-fc46dc96f841",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The SageMaker Model is a container containing the running environment + inference scripte + model data.\n",
    "# The SageMaker Endpoint is a running cluster of the SageMaker Models\n",
    "\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Change model_name (create one) and model_data (copy from the training job S3 model artifact) accordingly\n",
    "model_name = 'YOUR MODEL NAME'\n",
    "model_data = 'COPY FROM THE TRAINING JOB S3 MODEL ARTIFACT'\n",
    "endpoint_name = 'Whisper-zhtw'\n",
    "\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "        entry_point = 'inference.py',\n",
    "        source_dir='./scripts',\n",
    "        name = model_name,\n",
    "        transformers_version='4.17.0',\n",
    "        pytorch_version='1.10.2',\n",
    "        py_version='py38',\n",
    "        model_data=model_data,\n",
    "        role=ROLE,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c67e35-9034-433e-a9ed-c3f78020edb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The create_model method takes a lot of temporary space under the root. For large models, the root disk in SageMaker Studio Notebook (which is a container) is not enough. \n",
    "# This notebook is simply invoking SageMaker APIs, so it can be done on a EC2 as well.\n",
    "\n",
    "# For creating a new model and deploy as a new endpoint, the easiest way is to call the deploy method under the model\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5d.2xlarge\",\n",
    "    endpoint_name = endpoint_name,\n",
    ")\n",
    "\n",
    "# If you want to update an existing endpoint with a new model, you \n",
    "# from sagemaker.predictor import Predictor\n",
    "# from sagemaker.serializers import DataSerializer\n",
    "# from sagemaker.deserializers import JSONDeserializer\n",
    "#\n",
    "# sess.create_model(\n",
    "#     model_name,\n",
    "#     ROLE,\n",
    "#     huggingface_model.prepare_container_def(\n",
    "#         instance_type='ml.m5d.2xlarge'\n",
    "#     )\n",
    "# )\n",
    "#\n",
    "# audio_serializer = DataSerializer(content_type='audio/x-audio')\n",
    "#\n",
    "# predictor = Predictor('whisper-zhtw', serializer=audio_serializer, deserializer=JSONDeserializer())\n",
    "# predictor.update_endpoint(model_name=endpoint_name, initial_instance_count=1, instance_type='ml.m5d.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8ad32-0a49-402e-9fa0-6adad7f2d2bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Do the prediction\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import DataSerializer\n",
    "\n",
    "audio_path = 'test-audio.flac'\n",
    "audio_serializer = DataSerializer(content_type='audio/x-audio')\n",
    "\n",
    "predictor = Predictor(endpoint_name, serializer=audio_serializer)\n",
    "with open(audio_path, \"rb\") as data_file:\n",
    "    audio_data = data_file.read()\n",
    "    \n",
    "prediction = predictor.predict(audio_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22494c28-a0c1-41cc-b101-d806de26ac6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction.decode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087a281-3c32-4a9a-a1e7-cbb13b46a510",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}